{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fourier transformation on the WAV file\n",
    "# Good ideas from here: https://stackoverflow.com/questions/23377665/python-scipy-fft-wav-files\n",
    "# http://myinspirationinformation.com/uncategorized/audio-signals-in-python/\n",
    "# https://stackoverflow.com/questions/23874017/calculate-fft-with-windowing-displacement-and-bandpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import blackman, hanning, hamming\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Size of each chunk for the FFT function to process\n",
    "chunk_size = 4096\n",
    "\n",
    "# Location of the song\n",
    "files_location = \"C:/Users/bre49823/Google Drive/AudioFiles/\"       #\"/Users/valentin/Documents/MusicEngine/wav/\"\n",
    "song_id = \"dt_16bars_102rap\"                                        #\"TARGET_Biz_Amulet\"\n",
    "\n",
    "# Returns the sample rate (in samples/sec) and data from a WAV file\n",
    "fs, soundtrack_data = wavfile.read(files_location + song_id + \".wav\")\n",
    "\n",
    "audio_data = soundtrack_data.T[0]                      # this is a two channel soundtrack, get only one of the tracks\n",
    "\n",
    "# Create a 5 second test file from the rap beats\n",
    "#audio_data = audio_data[0:(44100*5)]\n",
    "#wavfile.write(files_location + \"test.wav\", rate = 44100, data = audio_data)\n",
    "audio_data = audio_data[0:int(10 * fs)]      # keep only the first 10 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of windows is: ', 1968)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 441000 into shape (224,1968)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c3762558ca4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create an array shape needed for the FFT function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0maudio_data_complex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0maudio_data_complex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_data_complex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_per_second\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data_complex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msamples_per_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Create an array to hold the results from FFT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 441000 into shape (224,1968)"
     ]
    }
   ],
   "source": [
    "samples_per_second = 224\n",
    "\n",
    "# Create a hanning window with a defined sample length. It should be a power of 2, but less than 44100. Ideally around 2048\n",
    "window = hanning(int(len(audio_data) / samples_per_second))\n",
    "print(\"The number of windows is: \", len(window))\n",
    "\n",
    "# Create an array shape needed for the FFT function\n",
    "audio_data_complex = audio_data.astype(complex)\n",
    "audio_data_complex = audio_data_complex.reshape(samples_per_second, int(len(audio_data_complex)/samples_per_second))\n",
    "\n",
    "# Create an array to hold the results from FFT\n",
    "fft_raw_array = np.empty([samples_per_second, int(len(audio_data)/samples_per_second)], dtype = complex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hanning window to apply FFT\n",
    "for i in range(samples_per_second):\n",
    "    fft_raw_array[i,:] = fft(audio_data_complex[i,:] * window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten the array - the resulting array will be as long as the original audio file\n",
    "fft_raw_array = fft_raw_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Fourier Transform creates a imaginary. The symmetry of the complex Fourier transform is very important\n",
    "# A real time domain signal corresponds to a frequency spectrum with an even real part, and an odd imaginary part (http://www.analog.com/media/en/technical-documentation/dsp-book/dsp_book_Ch31.pdf)\n",
    "# We only need the real data solution, so we can grab the first half, then calculate the frequency and plot the frequency against a scaled amplitude\n",
    "length_audio_data = len(audio_data)\n",
    "fft_transformed_real = fft_raw_array[0:int(length_audio_data / 2)]\n",
    "\n",
    "# Scale by the number of observations so that the magnitude does not depend on the length\n",
    "fft_transformed_real_scaled = fft_transformed_real / float(length_audio_data)\n",
    "\n",
    "# Calculate the frequency at each point in Hz\n",
    "frequency_of_song = np.arange(0, (length_audio_data / 2), 1.0) * (int(fs) / length_audio_data)\n",
    "\n",
    "# Calculate power\n",
    "power_db = 10 * np.log10(fft_transformed_real_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 13))\n",
    "plt.plot(frequency_of_song / 1000, power_db, color = '#ff0000', linewidth = 0.01)\n",
    "plt.xlabel(\"Frequency (kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
