{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a notebook about analyzing music files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Fourier transformation on the WAV file\n",
    "# Good ideas from here: https://stackoverflow.com/questions/23377665/python-scipy-fft-wav-files\n",
    "# http://myinspirationinformation.com/uncategorized/audio-signals-in-python/\n",
    "# https://stackoverflow.com/questions/34742225/how-to-extract-data-from-a-wav-file-using-python-matplotlib-library\n",
    "# https://stackoverflow.com/questions/2648151/python-frequency-detection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import blackman, hanning, hamming\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Size of each chunk for the FFT function to process\n",
    "chunk_size = 4096\n",
    "\n",
    "# Location of the song\n",
    "files_location = \"/Users/valentin/Documents/MusicEngine/wav/\"     #\"/Users/valentin/Documents/MusicEngine/wav/\"\n",
    "song_id = \"TARGET_Biz_Amulet\"                                        #\"TARGET_Biz_Amulet\"\n",
    "\n",
    "# Returns the sample rate (in samples/sec) and data from a WAV file\n",
    "fs, soundtrack_data = wavfile.read(files_location + song_id + \".wav\")\n",
    "audio_data = soundtrack_data.T[0]                      # this is a two channel soundtrack, get only one of the tracks\n",
    "audio_data = audio_data[1:(44100*5+1)]\n",
    "\n",
    "audio_data.dtype                                       # the data is stored as int16, i.e. the sound is 16 bit\n",
    "soundtrack_length = len(soundtrack_data) / fs          # calculate length of soundtrack in seconds\n",
    "\n",
    "\n",
    "# Plot the signal in the time domain\n",
    "time = np.arange(0, float(soundtrack_data.shape[0]), 1) / fs\n",
    "\n",
    "# Plot amplitude (or loudness) over time\n",
    "plt.figure(figsize = (30, 20))\n",
    "plt.plot(time, soundtrack_data, linewidth = 0.1, alpha = 2, color='#ff0000')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "\n",
    "# Create Fourier transform - THIS NEEDS TO BE DONE IN CHUNKS OF 2048 or 4096\n",
    "fourier_transform = fft(audio_data)   # Calculate fourier transform (complex numbers list)\n",
    "window = hanning(round(len(audio_data)/chunk_size))\n",
    "#fourier_transform = fft( NEED TO ADD THE DATA HERE * window)\n",
    "\n",
    "d = int(len(fourier_transform) / 2)                 # Find the mid-point of FFT. I only need half of the fft list (the signal is symmetric)\n",
    "\n",
    "# Data exploration\n",
    "#print(fs)                                # Sampling rate\n",
    "#print(data.T.shape)                      \n",
    "#print(data.T[0].min(), data.T[0].max())  # min and max values for channel 1\n",
    "#print(data.T[1].min(), data.T[1].max())  # min and max values for channel 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The values in the data represent the amplitude of the wave (or the loudness of the audio)\n",
    "# The energy of the audio can be described by the sum of the absolute amplitude.\n",
    "# This will depend on the length of the audio, the sample rate and the volume of the audio\n",
    "# A better metric is the Power which is energy per second\n",
    "\n",
    "# Energy of music\n",
    "energy = np.sum(audio_data.astype(float) ** 2)\n",
    "\n",
    "# Power - energy per unit of time\n",
    "power = 1.0 / (2 * (audio_data.size) + 1) * np.sum(audio_data.astype(float) ** 2) / fs\n",
    "\n",
    "print (\"Energy of music is: \", energy, \"\\nThe power of the music is: \", power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the FFT\n",
    "#plt.yscale('log')\n",
    "plt.figure(figsize = (30, 20))\n",
    "plt.plot(abs(fourier_transform[:(d - 1)]), linewidth = 0.08, alpha = 3, color = '#ff0000') \n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Amplitude\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Fourier Transform creates a imaginary. The symmetry of the complex Fourier transform is very important\n",
    "# A real time domain signal corresponds to a frequency spectrum with an even real part, and an odd imaginary part (http://www.analog.com/media/en/technical-documentation/dsp-book/dsp_book_Ch31.pdf)\n",
    "# We only need the real data solution, so we can grab the first half, then calculate the frequency and plot the frequency against a scaled amplitude\n",
    "length_audio_data = len(audio_data)\n",
    "fourier_transform_real_part = fourier_transform[0:int(length_audio_data / 2)]\n",
    "\n",
    "# Scale by the number of observations so that the magnitude does not depend on the length\n",
    "fourier_transform_real_part_scaled = fourier_transform_real_part / float(length_audio_data)\n",
    "\n",
    "# Calculate the frequency at each point in Hz\n",
    "frequency_of_song = np.arange(0, (length_audio_data / 2), 1.0) * (int(fs) / length_audio_data)\n",
    "\n",
    "# Calculate power\n",
    "power_db = 10 * np.log10(fourier_transform_real_part_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(fourier_transform_real_part)\n",
    "#fourier_transform_real_part.max(), fourier_transform_real_part.min()\n",
    "print (fourier_transform_real_part_scaled.max(), fourier_transform_real_part_scaled.min())\n",
    "print (frequency_of_song.max(), frequency_of_song.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 20))\n",
    "plt.plot(frequency_of_song / 1000, power_db, color = '#ff0000', linewidth = 0.08)\n",
    "plt.xlabel(\"Frequency (kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a spectrogram\n",
    "# Location of the song\n",
    "files_location = \"/Users/valentin/Documents/MusicEngine/wav/\"     #\"/Users/valentin/Documents/MusicEngine/wav/\"\n",
    "song_id = \"SIOiqyC9vQE\"                                     #\"TARGET_Biz_Amulet\"; Suzanita - 2kvAahQmWnc\n",
    "\n",
    "\n",
    "# Returns the sample rate (in samples/sec) and data from a WAV file\n",
    "fs, soundtrack_data = wavfile.read(files_location + song_id + \".wav\")\n",
    "audio_data = soundtrack_data.T                      # this is a two channel soundtrack, get only one of the tracks\n",
    "\n",
    "plt.figure(2, figsize = (30, 20))\n",
    "Pxx, freqs, bins, im = plt.specgram(audio_data,\n",
    "                                    Fs = fs,\n",
    "                                    NFFT = 1024,\n",
    "                                    #window = window_hanning(),\n",
    "                                    cmap = plt.get_cmap('autumn_r'))\n",
    "#cbar = plt.colorbar(im)\n",
    "#plt.xlabel('Time (s)')\n",
    "#plt.ylabel('Frequency (Hz)')\n",
    "#cbar.set_label('Intensity dB')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine particular regions\n",
    "np.where(freqs == 1000)\n",
    "MHZ10 = Pxx[233,:]\n",
    "plt.plot(bins, MHZ10, color = '#ff7f00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(fourier_transform.shape, audio_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
