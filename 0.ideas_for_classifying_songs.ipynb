{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ideas for classifying songs\n",
    "\n",
    "0. Shazam algorithm from the paper\n",
    "\n",
    "1. Blog about analyzing music - Really good!\n",
    "http://myinspirationinformation.com/uncategorized/audio-signals-in-python/\n",
    "https://arxiv.org/pdf/1502.05417.pdf\n",
    "\n",
    "2. Use spectrogram images to classify songs - https://chatbotslife.com/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194\n",
    "The idea is to create images of the spectrograms of all songs and classify spectrograms, not the music data itself\n",
    "\n",
    "3. Good ideas and Python code for generating Mel spectrograms\n",
    "http://cs231n.stanford.edu/reports/2017/pdfs/22.pdf\n",
    "\n",
    "4. The most common method for creating song features is the Mel-Frequency Cepstral Coefficients (MFCCs). MFCCs are a short-time spectral decomposition of an audio signal that conveys the general frequency characteristics important to human hearing. While originally developed to decouple vocal excitation from vocal tract shape for automatic speech recognition (Oppenheim, 1969), they have found applications in other auditory domains including music retrieval (Logan, 2000; Foote, 1997). At the recommendation of Aucouturier and Pachet (2004), we used 20-coefficient MFCCs.\n",
    "\n",
    "--> Paper which uses the MFCC\n",
    "https://www.researchgate.net/profile/Michael_Mandel/publication/220723596_Song-Level_Features_and_Support_Vector_Machines_for_Music_Classification/links/02e7e520c4c288e07d000000/Song-Level-Features-and-Support-Vector-Machines-for-Music-Classification.pdf\n",
    "\n",
    "5. Good paper which uses RBMs to classify songs (uses MFCC)\n",
    "https://courses.engr.illinois.edu/ece544na/fa2014/Tao_Feng.pdf\n",
    "\n",
    "6. Uses CNN to classify songs. The main song classification features are MFCCs\n",
    "http://www.iaeng.org/publication/IMECS2010/IMECS2010_pp546-550.pdf\n",
    "\n",
    "7. Song-level features and SVMs for music classification\n",
    "http://m.mr-pc.org/work/ismir05poster.pdf\n",
    "\n",
    "8. Deep Image Features in Music Information Retrieval\n",
    "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiGtqm3zb7WAhXDJcAKHYVdDLEQFggoMAA&url=http%3A%2F%2Fyadda.icm.edu.pl%2Fyadda%2Felement%2Fbwmeta1.element.baztech-d8639001-5f16-479a-99a6-91ecda6372db%2Fc%2FGwardys.pdf&usg=AFQjCNFuFFs8Q3HVjYmMUxR_zNh8B05IsA\n",
    "\n",
    "9. This paper uses MARSYAS to generate 30 song features, which are then used as predictors\n",
    "http://haralick.org/ML/A_machine_learning_approach_to_automatic_music_genre_classification.pdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
