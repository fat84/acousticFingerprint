{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a notebook about analyzing music files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a spectrogram using Mel cepstral filter\n",
    "\n",
    "# From Wikipedia: https://en.wikipedia.org/wiki/Mel-frequency_cepstrum\n",
    "# In sound processing, the mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum\n",
    "# of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency.\n",
    "\n",
    "# The code below is from http://cs231n.stanford.edu/reports/2017/pdfs/22.pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The librosa.display module needs to be explicitly imported (https://github.com/librosa/librosa/issues/441)\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "files_location = \"C:/Users/bre49823/GitRepo/MusicEngine/\"\n",
    "song_id = \"dt_16bars_102rap\"\n",
    "\n",
    "song_path = files_location + song_id + \".wav\"\n",
    "\n",
    "y , sr = librosa.load(song_path, mono = True)\n",
    "\n",
    "# Create Mel spectrogram\n",
    "M = librosa.feature.melspectrogram(\n",
    "    y = y,\n",
    "    sr = sr,\n",
    "    n_mels = 128,\n",
    "    n_fft = 2048,\n",
    "    hop_length = 1024)\n",
    "\n",
    "spectogram = librosa.power_to_db(\n",
    "    M , ref = np.max)\n",
    "\n",
    "# Plot Mel spectrogram\n",
    "plt.figure(figsize = (10, 4))\n",
    "librosa.display.specshow(spectogram,\n",
    "                         y_axis = 'mel', fmax = 20000,\n",
    "                         x_axis = 'time')\n",
    "plt.colorbar(format = '%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Fourier transformation on the WAV file\n",
    "# source: https://stackoverflow.com/questions/23377665/python-scipy-fft-wav-files\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "files_location = \"C:/Users/bre49823/GitRepo/MusicEngine/\"\n",
    "song_id = \"dt_16bars_102rap\"\n",
    "\n",
    "# Returns the sample rate (in samples/sec) and data from a WAV file\n",
    "fs, data = wavfile.read(files_location + song_id + \".wav\")\n",
    "\n",
    "a = data.T[0]                                     # this is a two channel soundtrack, I get the first track\n",
    "\n",
    "# this is 8-bit track, b is now normalized on [-1,1) -> !!! - How to figure out if it's 8- or 16-bit ????\n",
    "b = [(ele / 2 ** 8.) * 2 - 1 for ele in a]        \n",
    "min(b), max(b)\n",
    "\n",
    "c = scipy.fftpack.fft(b)                          # calculate fourier transform (complex numbers list)\n",
    "d = len(c)/2                                      # you only need half of the fft list (real signal symmetry)\n",
    "\n",
    "# Data exploration\n",
    "print(fs)                                # Sampling rate\n",
    "print(data.T.shape)                      \n",
    "print(data.T[0].min(), data.T[0].max())  # min and max values for channel 1\n",
    "print(data.T[1].min(), data.T[1].max())  # min and max values for channel 2\n",
    "\n",
    "\n",
    "# Plot the input signal here (from https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize(16, 5))\n",
    "#ax1.plot(x); ax1.set_title(\"Raw Audio Signal\")\n",
    "#ax2.specgram(x); ax2.set_title(\"Spectrogram\");\n",
    "\n",
    "\n",
    "# Plot of spectrogram\n",
    "plt.plot(abs(c[:(d-1)]),'r') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# For the correct output, convert the xlabelto the frequency for the spectrum plot\n",
    "k = scipy.arange(len(data))\n",
    "T = len(data)/fs  # where fs is the sampling frequency\n",
    "frqLabel = k/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experiment with reading and writing a file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from scipy.io import wavfile\n",
    "\n",
    "files_location = \"C:/Users/bre49823/GitRepo/MusicEngine/\"\n",
    "song_id = \"dt_16bars_102rap\"\n",
    "\n",
    "# Returns the sample rate (in samples/sec) and data from a WAV file\n",
    "fs, data = wavfile.read(files_location + song_id + \".wav\")\n",
    "\n",
    "print(fs)\n",
    "print(data.T.shape)\n",
    "print(data.T[0].min(), data.T[0].max())\n",
    "print(data.T[1].min(), data.T[1].max())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "wavfile.write(files_location + \"test\" + \".wav\", 44100, data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "files_location = \"C:/Users/bre49823/GitRepo/MusicEngine/\"\n",
    "song_id = \"dt_16bars_102rap\"\n",
    "\n",
    "# Returns the sample rate (in samples/sec) and data from a WAV file\n",
    "fs, data = io.wavfile.read(files_location + song_id + \".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from numpy.fft import fft, fftshift\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "window = np.hanning(120)\n",
    "plt.plot(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/2648151/python-frequency-detection\n",
    "  \n",
    "# Read in a WAV and find the freq's\n",
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "chunk = 2048\n",
    "\n",
    "# open up a wave\n",
    "wf = wave.open('test-tones/440hz.wav', 'rb')\n",
    "swidth = wf.getsampwidth()\n",
    "RATE = wf.getframerate()\n",
    "# use a Blackman window\n",
    "window = np.blackman(chunk)\n",
    "# open stream\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format =\n",
    "                p.get_format_from_width(wf.getsampwidth()),\n",
    "                channels = wf.getnchannels(),\n",
    "                rate = RATE,\n",
    "                output = True)\n",
    "\n",
    "# read some data\n",
    "data = wf.readframes(chunk)\n",
    "# play stream and find the frequency of each chunk\n",
    "while len(data) == chunk*swidth:\n",
    "    # write data out to the audio stream\n",
    "    stream.write(data)\n",
    "    # unpack the data and times by the hamming window\n",
    "    indata = np.array(wave.struct.unpack(\"%dh\"%(len(data)/swidth),\\\n",
    "                                         data))*window\n",
    "    # Take the fft and square each value\n",
    "    fftData=abs(np.fft.rfft(indata))**2\n",
    "    # find the maximum\n",
    "    which = fftData[1:].argmax() + 1\n",
    "    # use quadratic interpolation around the max\n",
    "    if which != len(fftData)-1:\n",
    "        y0,y1,y2 = np.log(fftData[which-1:which+2:])\n",
    "        x1 = (y2 - y0) * .5 / (2 * y1 - y2 - y0)\n",
    "        # find the frequency and output it\n",
    "        thefreq = (which+x1)*RATE/chunk\n",
    "        print \"The freq is %f Hz.\" % (thefreq)\n",
    "    else:\n",
    "        thefreq = which*RATE/chunk\n",
    "        print \"The freq is %f Hz.\" % (thefreq)\n",
    "    # read some more data\n",
    "    data = wf.readframes(chunk)\n",
    "if data:\n",
    "    stream.write(data)\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features from WAV file\n",
    "# source: https://stackoverflow.com/questions/34742225/how-to-extract-data-from-a-wav-file-using-python-matplotlib-library\n",
    "\n",
    "\"\"\" This work is licensed under a Creative Commons Attribution 3.0 Unported License.\n",
    "Frank Zalkow, 2012-2013 \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "from numpy.lib import stride_tricks\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\"\"\" short time fourier transform of audio signal \"\"\"\n",
    "def stft(sig, frameSize, overlapFac = 0.5, window = np.hanning):\n",
    "    win = window(frameSize)\n",
    "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
    "\n",
    "    # zeros at beginning (thus center of 1st window should be for sample nr. 0)\n",
    "    samples = np.append(np.zeros(np.floor(frameSize / 2.0)), sig)    \n",
    "    # cols for windowing\n",
    "    cols = np.ceil( (len(samples) - frameSize) / float(hopSize)) + 1\n",
    "    # zeros at end (thus samples can be fully covered by frames)\n",
    "    samples = np.append(samples, np.zeros(frameSize))\n",
    "\n",
    "    frames = stride_tricks.as_strided(samples, shape = (cols, frameSize), strides = (samples.strides[0] * hopSize, samples.strides[0])).copy()\n",
    "    frames *= win\n",
    "\n",
    "    return np.fft.rfft(frames)    \n",
    "\n",
    "\n",
    "\"\"\" scale frequency axis logarithmically \"\"\"    \n",
    "def logscale_spec(spec, sr = 44100, factor = 20.):\n",
    "    timebins, freqbins = np.shape(spec)\n",
    "\n",
    "    scale = np.linspace(0, 1, freqbins) ** factor\n",
    "    scale *= (freqbins - 1) / max(scale)\n",
    "    scale = np.unique(np.round(scale))\n",
    "\n",
    "    # create spectrogram with new freq bins\n",
    "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale) - 1:\n",
    "            newspec[:,i] = np.sum(spec[:, scale[i]:], axis = 1)\n",
    "        else:        \n",
    "            newspec[:,i] = np.sum(spec[:, scale[i]:scale[i + 1]], axis = 1)\n",
    "\n",
    "    # list center freq of bins\n",
    "    allfreqs = np.abs(np.fft.fftfreq(freqbins * 2, 1. / sr)[: freqbins + 1])\n",
    "    freqs = []\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale) - 1:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:])]\n",
    "        else:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:scale[i + 1]])]\n",
    "\n",
    "    return newspec, freqs\n",
    "\n",
    "\n",
    "\"\"\" plot spectrogram\"\"\"\n",
    "def plotstft(audiopath, binsize = 2 ** 10, plotpath = None, colormap = \"jet\"):\n",
    "    samplerate, samples = wav.read(audiopath)\n",
    "    s = stft(samples, binsize)\n",
    "\n",
    "    sshow, freq = logscale_spec(s, factor = 1.0, sr = samplerate)\n",
    "    ims = 20. * np.log10(np.abs(sshow) / 10e-6) # amplitude to decibel\n",
    "\n",
    "    timebins, freqbins = np.shape(ims)\n",
    "\n",
    "    plt.figure(figsize = (15, 7.5))\n",
    "    plt.imshow(np.transpose(ims), origin = \"lower\", aspect = \"auto\", cmap = colormap, interpolation = \"none\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    plt.ylabel(\"frequency (hz)\")\n",
    "    plt.xlim([0, timebins - 1])\n",
    "    plt.ylim([0, freqbins])\n",
    "\n",
    "    xlocs = np.float32(np.linspace(0, timebins - 1, 5))\n",
    "    plt.xticks(xlocs, [\"%.02f\" % l for l in ((xlocs * len(samples) / timebins) + (0.5 * binsize)) / samplerate])\n",
    "    ylocs = np.int16(np.round(np.linspace(0, freqbins - 1, 10)))\n",
    "    plt.yticks(ylocs, [\"%.02f\" % freq[i] for i in ylocs])\n",
    "\n",
    "    if plotpath:\n",
    "        plt.savefig(plotpath, bbox_inches = \"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "files_location = \"/Users/valentin/Documents/MusicEngine/wav/\"\n",
    "song_id = \"TARGET_Biz_Amulet\"\n",
    "\n",
    "plotstft(files_location + song_id + \".wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
